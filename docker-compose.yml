services:
  db:
    image: mariadb:11
    environment:
      MARIADB_ROOT_PASSWORD: ${DB_ROOT_PASSWORD}
      MARIADB_DATABASE: ${DB_NAME}
      MARIADB_USER: ${DB_USER}
      MARIADB_PASSWORD: ${DB_PASSWORD}
    ports:
      - "3307:3306"
    volumes:
      - db_data:/var/lib/mysql
      - ./db/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "healthcheck.sh", "--connect", "--innodb_initialized"]
      interval: 5s
      timeout: 5s
      retries: 20

  adminer:
    image: adminer:4
    ports:
      - "8080:8080"
    depends_on:
      - db

  crawler:
    build: ./crawler
    working_dir: /app
    volumes:
      - ./crawler:/app
    environment:
      DB_HOST: db
      DB_PORT: 3306
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
    depends_on:
      db:
        condition: service_healthy

  crawler_scheduler:
    build: ./crawler
    working_dir: /app
    volumes:
      - ./crawler:/app
    environment:
      DB_HOST: db
      DB_PORT: 3306
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      CRAWL_EVERY_MIN: ${CRAWL_EVERY_MIN}
      CLOSESPIDER_PAGECOUNT: ${CLOSESPIDER_PAGECOUNT}
    depends_on:
      db:
        condition: service_healthy
    command: >
      sh -c "
      while true; do
        echo '[scheduler] running spider...';
        scrapy crawl lrt_queue -s LOG_LEVEL=INFO -s CLOSESPIDER_PAGECOUNT=$${CLOSESPIDER_PAGECOUNT};
        echo '[scheduler] sleep...';
        sleep $$(($${CRAWL_EVERY_MIN} * 60));
      done
      "


volumes:
  db_data:
